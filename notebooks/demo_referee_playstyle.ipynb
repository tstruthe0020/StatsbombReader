{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referee-Playstyle-Discipline Analytics Demo\n",
    "\n",
    "This notebook demonstrates the comprehensive referee analytics system that models how team playstyles affect disciplinary outcomes by referee, with spatial zone analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our modules\n",
    "from src.io_load import StatsBombLoader\n",
    "from src.features import PlaystyleFeatureExtractor\n",
    "from src.discipline import DisciplineAnalyzer\n",
    "from src.modeling_zone_nb import ZoneNBModeler\n",
    "from src.viz_referee import RefereeVisualizer\n",
    "from backend.server import GitHubAPIClient\n",
    "\n",
    "# Setup\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Feature Engineering\n",
    "\n",
    "Load StatsBomb data and extract playstyle and discipline features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Default competitions: {len(config['default_analysis']['competitions'])}\")\n",
    "print(f\"- Zone grid: {config['features']['discipline']['zones']['x_bins']}x{config['features']['discipline']['zones']['y_bins']}\")\n",
    "print(f\"- Interaction features: {config['modeling']['zone_nb']['interaction_features']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components (you'll need to provide GitHub token)\n",
    "GITHUB_TOKEN = \"your_github_token_here\"  # Replace with actual token\n",
    "\n",
    "# Initialize clients\n",
    "github_client = GitHubAPIClient(GITHUB_TOKEN)\n",
    "loader = StatsBombLoader(github_client, cache_dir=\"../data/cache\")\n",
    "\n",
    "# Initialize analyzers\n",
    "feature_extractor = PlaystyleFeatureExtractor(config['features']['playstyle'])\n",
    "discipline_analyzer = DisciplineAnalyzer(config['features']['discipline'])\n",
    "\n",
    "print(\"✓ Data loading components initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Match Analysis\n",
    "\n",
    "Analyze a single match to demonstrate feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample matches from La Liga\n",
    "try:\n",
    "    matches_df = loader.get_matches(11, 90)  # La Liga 2020/21\n",
    "    sample_match = matches_df.iloc[0]\n",
    "    \n",
    "    print(f\"Sample match: {sample_match['home_team_name']} vs {sample_match['away_team_name']}\")\n",
    "    print(f\"Date: {sample_match['match_date']}\")\n",
    "    print(f\"Referee: {sample_match.get('referee_name', 'Unknown')}\")\n",
    "    \n",
    "    # Load events for this match\n",
    "    events_df = loader.get_events(sample_match['match_id'])\n",
    "    print(f\"Events loaded: {len(events_df)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading sample data: {e}\")\n",
    "    print(\"This is expected if GitHub token is not provided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both teams (if data is available)\n",
    "if 'events_df' in locals() and not events_df.empty:\n",
    "    home_team = sample_match['home_team_name']\n",
    "    away_team = sample_match['away_team_name']\n",
    "    \n",
    "    # Extract playstyle features\n",
    "    home_playstyle = feature_extractor.extract_team_match_features(\n",
    "        events_df, home_team, away_team\n",
    "    )\n",
    "    \n",
    "    # Extract discipline features\n",
    "    home_discipline = discipline_analyzer.extract_team_match_discipline(\n",
    "        events_df, home_team, away_team\n",
    "    )\n",
    "    \n",
    "    print(\"Home Team Playstyle Features:\")\n",
    "    for key, value in list(home_playstyle.items())[:8]:\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    \n",
    "    print(\"\\nHome Team Discipline Features:\")\n",
    "    for key, value in list(home_discipline.items())[:8]:\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"Skipping feature extraction - no sample data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Zone-wise Modeling Demo\n",
    "\n",
    "Demonstrate the statistical modeling approach with synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset for demonstration\n",
    "np.random.seed(42)\n",
    "\n",
    "n_matches = 200\n",
    "referees = ['Referee A', 'Referee B', 'Referee C', 'Referee D', 'Referee E']\n",
    "\n",
    "# Generate synthetic team-match data\n",
    "synthetic_data = []\n",
    "\n",
    "for i in range(n_matches):\n",
    "    referee = np.random.choice(referees)\n",
    "    \n",
    "    # Base features (standardized)\n",
    "    z_directness = np.random.normal(0, 1)\n",
    "    z_ppda = np.random.normal(0, 1)\n",
    "    z_possession_share = np.random.normal(0, 1)\n",
    "    z_block_height_x = np.random.normal(0, 1)\n",
    "    z_wing_share = np.random.normal(0, 1)\n",
    "    \n",
    "    # Referee effects (some referees are stricter)\n",
    "    referee_effect = {'Referee A': 1.2, 'Referee B': 0.8, 'Referee C': 1.0, \n",
    "                     'Referee D': 1.1, 'Referee E': 0.9}[referee]\n",
    "    \n",
    "    # Home/away\n",
    "    home_away = np.random.choice(['home', 'away'])\n",
    "    home_indicator = 1 if home_away == 'home' else 0\n",
    "    \n",
    "    # Exposure\n",
    "    opp_passes = np.random.poisson(400)\n",
    "    log_opp_passes = np.log(opp_passes)\n",
    "    \n",
    "    # Generate fouls for each zone with referee interactions\n",
    "    row = {\n",
    "        'match_id': 1000 + i,\n",
    "        'team': f'Team_{i % 20}',\n",
    "        'referee_name': referee,\n",
    "        'home_away': home_away,\n",
    "        'home_indicator': home_indicator,\n",
    "        'z_directness': z_directness,\n",
    "        'z_ppda': z_ppda,\n",
    "        'z_possession_share': z_possession_share,\n",
    "        'z_block_height_x': z_block_height_x,\n",
    "        'z_wing_share': z_wing_share,\n",
    "        'opp_passes': opp_passes,\n",
    "        'log_opp_passes': log_opp_passes\n",
    "    }\n",
    "    \n",
    "    # Generate zone-specific fouls\n",
    "    for x in range(5):\n",
    "        for y in range(3):\n",
    "            # Base rate varies by zone (more fouls in middle third)\n",
    "            base_rate = 0.5 + (1.0 if x in [1, 2, 3] else 0.2)\n",
    "            \n",
    "            # Add feature effects and referee interactions\n",
    "            linear_pred = (base_rate + \n",
    "                          0.2 * z_directness + \n",
    "                          0.15 * z_ppda +\n",
    "                          0.1 * home_indicator +\n",
    "                          0.2 * np.log(referee_effect))\n",
    "            \n",
    "            # Add referee-specific directness interaction\n",
    "            if referee == 'Referee A':  # Stricter on direct play\n",
    "                linear_pred += 0.3 * z_directness\n",
    "            elif referee == 'Referee B':  # More lenient on direct play\n",
    "                linear_pred -= 0.2 * z_directness\n",
    "            \n",
    "            # Generate count with exposure\n",
    "            lambda_param = np.exp(linear_pred + log_opp_passes - np.log(400))  # Normalize exposure\n",
    "            fouls = np.random.poisson(max(0.1, lambda_param))\n",
    "            \n",
    "            row[f'foul_grid_x{x}_y{y}'] = fouls\n",
    "    \n",
    "    synthetic_data.append(row)\n",
    "\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "print(f\"Created synthetic dataset: {len(synthetic_df)} team-matches\")\n",
    "print(f\"Referees: {synthetic_df['referee_name'].nunique()}\")\n",
    "print(f\"Total fouls: {synthetic_df[[c for c in synthetic_df.columns if c.startswith('foul_grid')]].sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit Zone-wise Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit models\n",
    "modeler = ZoneNBModeler(config)\n",
    "\n",
    "# Prepare data\n",
    "df_prepared, prep_info = modeler.prepare_modeling_data(synthetic_df)\n",
    "print(f\"Data prepared: {prep_info}\")\n",
    "\n",
    "# Fit models\n",
    "print(\"\\nFitting zone-wise NB models...\")\n",
    "fitted_models = modeler.fit_zone_nb_models(\n",
    "    df_prepared,\n",
    "    feature_list=['z_directness', 'z_ppda', 'z_possession_share'],\n",
    "    interaction_features=['directness']\n",
    ")\n",
    "\n",
    "print(f\"Successfully fitted {len(fitted_models)} zone models\")\n",
    "\n",
    "# Get diagnostics\n",
    "diagnostics = modeler.get_model_diagnostics()\n",
    "print(f\"\\nModel Diagnostics:\")\n",
    "print(f\"- Convergence rate: {diagnostics['convergence_rate']:.1%}\")\n",
    "print(f\"- Average AIC: {diagnostics['average_aic']:.2f}\")\n",
    "print(f\"- Zones analyzed: {len(diagnostics['zones_analyzed'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Referee Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract referee slopes for directness\n",
    "directness_slopes = modeler.extract_referee_slopes('directness')\n",
    "\n",
    "if not directness_slopes.empty:\n",
    "    print(\"Referee-specific directness effects:\")\n",
    "    print(directness_slopes.groupby('referee_name').agg({\n",
    "        'slope': 'mean',\n",
    "        'significant': 'sum'\n",
    "    }).round(3))\n",
    "else:\n",
    "    print(\"No interaction slopes found (expected with limited synthetic data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = RefereeVisualizer(config)\n",
    "\n",
    "# Create a simple heatmap showing expected fouls\n",
    "sample_team_features = {\n",
    "    'z_directness': 1.0,  # High directness\n",
    "    'z_ppda': 0.5,\n",
    "    'z_possession_share': -0.5,\n",
    "    'home_indicator': 1,\n",
    "    'referee_name': 'Referee A',\n",
    "    'log_opp_passes': np.log(400)\n",
    "}\n",
    "\n",
    "# Add zone columns with zeros (required for prediction)\n",
    "for x in range(5):\n",
    "    for y in range(3):\n",
    "        sample_team_features[f'foul_grid_x{x}_y{y}'] = 0\n",
    "\n",
    "# Predict expected fouls\n",
    "expected_fouls = modeler.predict_expected_fouls(pd.Series(sample_team_features))\n",
    "\n",
    "print(\"Expected fouls per zone for high-directness team with Referee A:\")\n",
    "for zone, fouls in expected_fouls.items():\n",
    "    print(f\"{zone}: {fouls:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic heatmap visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Create 5x3 grid\n",
    "foul_grid = np.zeros((3, 5))\n",
    "for zone_id, fouls in expected_fouls.items():\n",
    "    if zone_id.startswith('zone_'):\n",
    "        parts = zone_id.split('_')\n",
    "        x_zone = int(parts[1])\n",
    "        y_zone = int(parts[2])\n",
    "        foul_grid[2 - y_zone, x_zone] = fouls  # Flip y for proper orientation\n",
    "\n",
    "# Create heatmap\n",
    "im = ax.imshow(foul_grid, cmap='Reds', aspect='auto', extent=[0, 120, 0, 80])\n",
    "\n",
    "# Add values to cells\n",
    "for y in range(3):\n",
    "    for x in range(5):\n",
    "        value = foul_grid[y, x]\n",
    "        ax.text((x + 0.5) * 24, (y + 0.5) * 26.67, f'{value:.1f}', \n",
    "               ha='center', va='center', fontsize=12, fontweight='bold',\n",
    "               color='white' if value > np.max(foul_grid) * 0.5 else 'black')\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlim(0, 120)\n",
    "ax.set_ylim(0, 80)\n",
    "ax.set_xlabel('Field Length (m)')\n",
    "ax.set_ylabel('Field Width (m)')\n",
    "ax.set_title('Expected Fouls per Zone\\nHigh-Directness Team with Referee A', \n",
    "            fontsize=14, fontweight='bold')\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "cbar.set_label('Expected Fouls per Match', rotation=270, labelpad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total expected fouls: {np.sum(foul_grid):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "This demo has shown:\n",
    "\n",
    "1. **Feature Engineering**: Extraction of playstyle (directness, pressing, possession) and disciplinary features (fouls by zone)\n",
    "2. **Zone-wise Modeling**: Negative Binomial GLMs with referee interactions for each field zone\n",
    "3. **Prediction**: Expected foul counts based on team playstyle and referee\n",
    "4. **Visualization**: Heatmaps showing spatial distribution of expected fouls\n",
    "\n",
    "### To use with real data:\n",
    "\n",
    "1. **Provide GitHub token** for StatsBomb data access\n",
    "2. **Run dataset builder**: `python src/run_build_dataset.py --github-token YOUR_TOKEN`\n",
    "3. **Fit models**: `python src/run_fit_models.py --dataset data/team_match_features.parquet`\n",
    "4. **Generate reports**: `python src/run_report.py --models-dir data/models_nb_zone --heatmap --referee \"Referee Name\" --feature directness`\n",
    "\n",
    "### Key insights from this system:\n",
    "\n",
    "- **Referee consistency**: Some referees are systematically stricter/more lenient\n",
    "- **Playstyle interactions**: Certain referees penalize specific playing styles more\n",
    "- **Spatial patterns**: Foul calling varies by field zone and referee\n",
    "- **Tactical intelligence**: Teams can adapt strategy based on referee assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}